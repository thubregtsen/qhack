{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "from pennylane.operation import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris dataset details on visual inspection:\n",
    "# 150 tuples, X and y\n",
    "# X having 4 features, np.min(X)=0; np.max(X)=7.9\n",
    "# y consisting of 3 classes: 0, 1, 2; stored in-order\n",
    "X, y = load_iris(return_X_y=True) \n",
    "\n",
    "# pick inputs and labels from the first two classes only,\n",
    "# corresponding to the first 100 samples\n",
    "# -> meanig y now consists of 2 classes: 0, 1; still stored in order, balanced 50:50\n",
    "X = X[:100,0:2]\n",
    "y = y[:100]\n",
    "\n",
    "# scaling the inputs is important since the embedding we use is periodic\n",
    "# -> data is scaled to np.min(X)=-2.307; np.max(X)= 2.731\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# scaling the labels to -1, 1 is important for the SVM and the\n",
    "# definition of a hinge loss\n",
    "# -> now making the 2 classes: -1, 1\n",
    "y_scaled = 2 * (y - 0.5)\n",
    "\n",
    "# -> result of train_test_split:\n",
    "# len(X_train)=75, 39 labelled 1, 36 labelled -1\n",
    "# len(X_test)=25\n",
    "# data is shuffled prior to split (shuffled variable in train_test_split is default True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = len(X_train[0]) # -> equals number of features\n",
    "n_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_kernel = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "projector = np.zeros((2**n_qubits, 2**n_qubits))\n",
    "projector[0, 0] = 1\n",
    "\n",
    "@qml.qnode(dev_kernel)\n",
    "def kernel(x1, x2):\n",
    "    \n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    AngleEmbedding(x1, wires=range(n_qubits))\n",
    "    qml.inv(AngleEmbedding(x2, wires=range(n_qubits)))\n",
    "    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the kernel using the quantum machine\n",
    "# kernel computed by k(a,b) for all A and B\n",
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually computer the kernel (on the quantum machine) using the scikit framework\n",
    "svm = SVC(kernel=kernel_matrix).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_kernel.num_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_indices = svm.support_\n",
    "print(\"The following indeces are the training samples used as support vectors:\\n\", sv_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Of these, \" + str(svm.n_support_[0]) + \" are for our first class and \" + str(svm.n_support_[1]) + \" are for our second class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_weights = svm.dual_coef_[0]\n",
    "print(\"They have the following weights:\\n\", sv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sample = i\n",
    "    print(\"Scikit prediction:\", svm.predict([X_test[sample]])[0])\n",
    "\n",
    "    result = 0\n",
    "    for feature_index in range(len(X_train[0])):\n",
    "        feature_sum = 0\n",
    "        for index in range(len(sv_indices)):\n",
    "            feature_sum += sv_weights[index]*X_train[sv_indices[index]]\n",
    "\n",
    "    print(\"Hacked prediction:\", np.sum(feature_sum)/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[np.where(y_train == 1)[0],0], X_train[np.where(y_train == 1)[0],1], color=\"b\", label=1)\n",
    "plt.scatter(X_train[np.where(y_train == -1)[0],0], X_train[np.where(y_train == -1)[0],1], color=\"r\", label=-1)\n",
    "plt.legend()\n",
    "#plt.scatter(X_train[sv_indices], X_train[sv_indices], color=\"k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[np.where(y_train == 1)[0],0], X_train[np.where(y_train == 1)[0],1], color=\"b\", label=\"1\")\n",
    "plt.scatter(X_train[np.where(y_train == -1)[0],0], X_train[np.where(y_train == -1)[0],1], color=\"r\", label=\"-1\")\n",
    "plt.scatter(X_train[sv_indices,0], X_train[sv_indices,1], color=\"k\", label=\"support vectors\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy dataset that uniformly spans the input space\n",
    "X_dummy = []\n",
    "for i in range(-10,10):\n",
    "    for j in range(-10,10):\n",
    "        X_dummy.append([np.pi*i/10,np.pi*j/10])\n",
    "X_dummy = np.asarray(X_dummy)\n",
    "print(len(X_dummy))\n",
    "\n",
    "# predict (about a minute on my laptop)\n",
    "y_dummy = svm.predict(X_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot in order to observe the decision boundary\n",
    "plt.scatter(X_dummy[np.where(y_dummy == 1)[0],0], X_dummy[np.where(y_dummy == 1)[0],1], color=\"b\")\n",
    "plt.scatter(X_dummy[np.where(y_dummy == -1)[0],0], X_dummy[np.where(y_dummy == -1)[0],1], color=\"r\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(svm.decision_function([X_train[i]]))\n",
    "    print(svm.predict([X_train[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[sv_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sum(sv_weights*X_train[sv_indices,0])/len(sv_indices)\n",
    "b = np.sum(sv_weights*X_train[sv_indices,1])/len(sv_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[kernel([a,b], X_train[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
